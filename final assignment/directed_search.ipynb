{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FF aan gabe vragen morgen, waarom wij geen waardes voor RfR krijgen, waardoor al die convergence shit niet werkt en we een andere problem formulation moeten gebruiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all modules, some might not be necessary (DIE NOG VERWIJDEREN)\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    MultiprocessingEvaluator,\n",
    "    ScalarOutcome,\n",
    "    IntegerParameter,\n",
    "    optimize,\n",
    "    Scenario,\n",
    "    Constraint,\n",
    ")\n",
    "from ema_workbench.em_framework.optimization import EpsilonProgress, epsilon_nondominated\n",
    "from ema_workbench.util import ema_logging\n",
    "\n",
    "from ema_workbench import (\n",
    "    HypervolumeMetric,\n",
    "    GenerationalDistanceMetric,\n",
    "    EpsilonIndicatorMetric,\n",
    "    InvertedGenerationalDistanceMetric,\n",
    "    SpacingMetric,\n",
    ")\n",
    "from ema_workbench.em_framework.optimization import to_problem, ArchiveLogger\n",
    "from custom_problem_formulation_no_RfR import get_model_for_problem_formulation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "model, steps = get_model_for_problem_formulation()\n",
    "problem = to_problem(model, searchover=\"levers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A.0_ID flood wave shape</th>\n",
       "      <th>A.1_Bmax</th>\n",
       "      <th>A.1_Brate</th>\n",
       "      <th>A.1_pfail</th>\n",
       "      <th>A.2_Bmax</th>\n",
       "      <th>A.2_Brate</th>\n",
       "      <th>A.2_pfail</th>\n",
       "      <th>A.3_Bmax</th>\n",
       "      <th>A.3_Brate</th>\n",
       "      <th>A.3_pfail</th>\n",
       "      <th>A.4_Bmax</th>\n",
       "      <th>A.4_Brate</th>\n",
       "      <th>A.4_pfail</th>\n",
       "      <th>A.5_Bmax</th>\n",
       "      <th>A.5_Brate</th>\n",
       "      <th>A.5_pfail</th>\n",
       "      <th>discount rate 0</th>\n",
       "      <th>discount rate 1</th>\n",
       "      <th>discount rate 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12275</th>\n",
       "      <td>26</td>\n",
       "      <td>210.807918</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.092027</td>\n",
       "      <td>172.374261</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>254.006564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915031</td>\n",
       "      <td>165.440227</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.235617</td>\n",
       "      <td>183.021862</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.342190</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39833</th>\n",
       "      <td>101</td>\n",
       "      <td>123.723596</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>315.055206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019649</td>\n",
       "      <td>34.954835</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.305029</td>\n",
       "      <td>145.432329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862907</td>\n",
       "      <td>209.075297</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35280</th>\n",
       "      <td>119</td>\n",
       "      <td>84.948477</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.294570</td>\n",
       "      <td>305.283047</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.702650</td>\n",
       "      <td>220.064913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.326005</td>\n",
       "      <td>49.619647</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>306.976860</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.426481</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20422</th>\n",
       "      <td>20</td>\n",
       "      <td>323.962775</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.190418</td>\n",
       "      <td>328.161863</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>302.061696</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.051706</td>\n",
       "      <td>289.845385</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.059208</td>\n",
       "      <td>83.701692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692434</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>104</td>\n",
       "      <td>40.525349</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.161001</td>\n",
       "      <td>187.789168</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>205.979011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958783</td>\n",
       "      <td>340.402481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086792</td>\n",
       "      <td>75.494126</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.826855</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             A.0_ID flood wave shape    A.1_Bmax  A.1_Brate  A.1_pfail  \\\n",
       "scenario_id                                                              \n",
       "12275                             26  210.807918        1.5   0.092027   \n",
       "39833                            101  123.723596       10.0   0.087285   \n",
       "35280                            119   84.948477       10.0   0.294570   \n",
       "20422                             20  323.962775        1.5   0.190418   \n",
       "4717                             104   40.525349       10.0   0.161001   \n",
       "\n",
       "               A.2_Bmax  A.2_Brate  A.2_pfail    A.3_Bmax  A.3_Brate  \\\n",
       "scenario_id                                                            \n",
       "12275        172.374261        1.5   0.517100  254.006564        1.0   \n",
       "39833        315.055206        1.0   0.019649   34.954835       10.0   \n",
       "35280        305.283047       10.0   0.702650  220.064913        1.0   \n",
       "20422        328.161863       10.0   0.014162  302.061696       10.0   \n",
       "4717         187.789168        1.5   0.010373  205.979011        1.0   \n",
       "\n",
       "             A.3_pfail    A.4_Bmax  A.4_Brate  A.4_pfail    A.5_Bmax  \\\n",
       "scenario_id                                                            \n",
       "12275         0.915031  165.440227       10.0   0.235617  183.021862   \n",
       "39833         0.305029  145.432329        1.0   0.862907  209.075297   \n",
       "35280         0.326005   49.619647        1.5   0.009365  306.976860   \n",
       "20422         0.051706  289.845385        1.5   0.059208   83.701692   \n",
       "4717          0.958783  340.402481        1.0   0.086792   75.494126   \n",
       "\n",
       "             A.5_Brate  A.5_pfail  discount rate 0  discount rate 1  \\\n",
       "scenario_id                                                           \n",
       "12275             10.0   0.342190              2.5              1.5   \n",
       "39833              1.5   0.009042              1.5              3.5   \n",
       "35280             10.0   0.426481              4.5              3.5   \n",
       "20422              1.0   0.692434              1.5              1.5   \n",
       "4717               1.5   0.826855              1.5              1.5   \n",
       "\n",
       "             discount rate 2  \n",
       "scenario_id                   \n",
       "12275                    3.5  \n",
       "39833                    3.5  \n",
       "35280                    1.5  \n",
       "20422                    3.5  \n",
       "4717                     1.5  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the selected scenarios\n",
    "scenarios_df = pd.read_csv('results/selected_scenarios.csv')\n",
    "scenarios_df.rename(columns={'Unnamed: 0': 'scenario_id'}, inplace=True)\n",
    "scenarios_df = scenarios_df.set_index('scenario_id')\n",
    "scenarios_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_ids = scenarios_df.index.to_list()\n",
    "archive_dict = {}\n",
    "results_dict = {}\n",
    "convergence_dict = {}\n",
    "amount_of_seeds = 4\n",
    "\n",
    "for scenario in scenario_ids:\n",
    "    archive_list = []\n",
    "    results_list = []\n",
    "    convergence_list = []\n",
    "    for i in range(amount_of_seeds):\n",
    "        archives = ArchiveLogger.load_archives(f\"./archive/Policy_search_arch_{float(scenario)}_seed{i}.tar.gz\")\n",
    "        for key, df in archives.items():\n",
    "            if 'Unnamed: 0' in df.columns:\n",
    "                del df['Unnamed: 0']\n",
    "            # Drop the 'A.1_RfR Costs' and 'A.2_RfR Costs' columns NOG ERGENS GOED UITLEGGEN WAAROM WE RFR DROPPEN\n",
    "            df.drop(['A.1_RfR Costs', 'A.2_RfR Costs'], axis=1, inplace=True)\n",
    "        archive_list.append(archives)\n",
    "\n",
    "        result = pd.read_csv(f\"./results/Policy_search_scen{float(scenario)}_seed{i}results.csv\", index_col=0)\n",
    "        # Drop the 'A.1_RfR Costs' and 'A.2_RfR Costs' columns\n",
    "        result.drop(['A.1_RfR Costs', 'A.2_RfR Costs'], axis=1, inplace=True)\n",
    "        results_list.append(result)\n",
    "\n",
    "        convergence = pd.read_csv(f\"./results/Policy_search_scen{float(scenario)}_seed{i}convergence.csv\", index_col=0)\n",
    "        convergence_list.append(convergence)\n",
    "\n",
    "    archive_dict[scenario] = archive_list\n",
    "    results_dict[scenario] = results_list\n",
    "    convergence_dict[scenario] = convergence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 100, 11012, 1195, 12014, 13017, 14072, 15127, 16131, 17131, 18136, 19139, 20032, 2293, 3389, 4481, 5577, 6675, 7772, 8867, 9960])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_dict[12275][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 12275 has 19 non-dominated policies\n",
      "Scenario 39833 has 348 non-dominated policies\n",
      "Scenario 35280 has 5 non-dominated policies\n",
      "Scenario 20422 has 128 non-dominated policies\n",
      "Scenario 4717 has 259 non-dominated policies\n"
     ]
    }
   ],
   "source": [
    "policy_dict = {}\n",
    "epsilon = [100, 100, 0.01, 100, 100, 100, 0.01, 100]\n",
    "for i in range(len(scenario_ids)):\n",
    "    df = epsilon_nondominated(results_dict[scenario_ids[i]], epsilon, problem) # This function doesn't work properly anymore, we had to change lines 893 and 895 in optimization.py in the em_framework\n",
    "    policy_dict[scenario_ids[i]] = df\n",
    "    n_policies = df.shape[0]\n",
    "    print(f\"Scenario {scenario_ids[i]} has {n_policies} non-dominated policies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 12275 has 71 unique policies\n",
      "Scenario 39833 has 1366 unique policies\n",
      "Scenario 35280 has 20 unique policies\n",
      "Scenario 20422 has 512 unique policies\n",
      "Scenario 4717 has 1026 unique policies\n"
     ]
    }
   ],
   "source": [
    "# Checking how many unique policies there were at first to get an idea of how many policies were removed\n",
    "for scenario in scenario_ids:\n",
    "    # Concatenate DataFrames for all seeds\n",
    "    df_all_seeds = pd.concat(results_dict[scenario])\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df_unique_policies = df_all_seeds.drop_duplicates()\n",
    "\n",
    "    # Print the number of unique policies\n",
    "    print(f\"Scenario {scenario} has {df_unique_policies.shape[0]} unique policies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con_metrics = {}\n",
    "# for scenario in scenario_ids:\n",
    "#     con_metrics[scenario] = []\n",
    "\n",
    "# for scenario in scenario_ids:\n",
    "#     con_metrics[scenario] = []\n",
    "\n",
    "#     hypervolum = HypervolumeMetric(policy_dict[scenario], problem)\n",
    "#     gen_dist = GenerationalDistanceMetric(policy_dict[scenario], problem, d=1)\n",
    "#     epsilon_ind = EpsilonIndicatorMetric(policy_dict[scenario], problem)\n",
    "#     inverted_gen_dist = InvertedGenerationalDistanceMetric(policy_dict[scenario], problem, d=1)\n",
    "#     spacing_met = SpacingMetric(problem)\n",
    "\n",
    "#     for archives in archive_list:\n",
    "#         metrics = []\n",
    "#         for nfe, archive in archives.items():\n",
    "#             scores = {\n",
    "#                 \"hypervolume\": hypervolum.calculate(archive),\n",
    "#                 \"generational_distance\": gen_dist.calculate(archive),\n",
    "#                 \"epsilon_indicator\": epsilon_ind.calculate(archive),\n",
    "#                 \"inverted_generational_distance\": inverted_gen_dist.calculate(archive),\n",
    "#                 \"spacing\": spacing_met.calculate(archive),\n",
    "#                 \"nfe\": int(nfe),\n",
    "#             }\n",
    "#             metrics.append(scores)\n",
    "#         metrics = pd.DataFrame.from_dict(metrics)\n",
    "\n",
    "#         # sort metrics by number of function evaluations\n",
    "#         metrics.sort_values(by=\"nfe\", inplace=True)\n",
    "#         con_metrics.append(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style(\"white\")\n",
    "# fig, axes = plt.subplots(nrows=6, figsize=(8, 12), sharex=True)\n",
    "\n",
    "# ax1, ax2, ax3, ax4, ax5, ax6 = axes\n",
    "\n",
    "# for metrics, convergence in zip(metrics_by_seed, convergences):\n",
    "#     ax1.plot(metrics.nfe, metrics.hypervolume)\n",
    "#     ax1.set_ylabel(\"hypervolume\")\n",
    "\n",
    "#     ax2.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "#     ax2.set_ylabel(\"$\\epsilon$ progress\")\n",
    "\n",
    "#     ax3.plot(metrics.nfe, metrics.generational_distance)\n",
    "#     ax3.set_ylabel(\"generational distance\")\n",
    "\n",
    "#     ax4.plot(metrics.nfe, metrics.epsilon_indicator)\n",
    "#     ax4.set_ylabel(\"epsilon indicator\")\n",
    "\n",
    "#     ax5.plot(metrics.nfe, metrics.inverted_gd)\n",
    "#     ax5.set_ylabel(\"inverted generational\\ndistance\")\n",
    "\n",
    "#     ax6.plot(metrics.nfe, metrics.spacing)\n",
    "#     ax6.set_ylabel(\"spacing\")\n",
    "\n",
    "# ax6.set_xlabel(\"nfe\")\n",
    "\n",
    "\n",
    "# sns.despine(fig)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate convergence metrics\n",
    "convergence_metrics = {}\n",
    "for scenario in scenario_ids:\n",
    "    pols = policy_dict[scenario]\n",
    "    hv = HypervolumeMetric(pols, problem)\n",
    "    gd = GenerationalDistanceMetric(pols, problem, d=1)\n",
    "    ei = EpsilonIndicatorMetric(pols, problem)\n",
    "    ig = InvertedGenerationalDistanceMetric(pols, problem, d=1)\n",
    "    sm = SpacingMetric(problem)\n",
    "\n",
    "    convergence_metrics[scenario] = []\n",
    "\n",
    "    for archive in archive_dict[scenario]:\n",
    "        metrics = []\n",
    "        for nfe, a in archive.items():\n",
    "            scores = {\n",
    "                \"generational_distance\": gd.calculate(a),\n",
    "                \"hypervolume\": hv.calculate(a),\n",
    "                \"epsilon_indicator\": ei.calculate(a),\n",
    "                \"inverted_gd\": ig.calculate(a),\n",
    "                \"spacing\": sm.calculate(a),\n",
    "                \"nfe\": int(nfe),\n",
    "            }\n",
    "            metrics.append(scores)\n",
    "        metrics = pd.DataFrame.from_dict(metrics)\n",
    "\n",
    "        # sort metrics by number of function evaluations\n",
    "        metrics.sort_values(by=\"nfe\", inplace=True)\n",
    "        convergence_metrics[scenario].append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "fig, axes = plt.subplots(nrows=6, figsize=(8, 12), sharex=True)\n",
    "\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes\n",
    "\n",
    "for metrics, convergence in zip(metrics_by_seed, convergences):\n",
    "    ax1.plot(metrics.nfe, metrics.hypervolume)\n",
    "    ax1.set_ylabel(\"hypervolume\")\n",
    "\n",
    "    ax2.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "    ax2.set_ylabel(\"$\\epsilon$ progress\")\n",
    "\n",
    "    ax3.plot(metrics.nfe, metrics.generational_distance)\n",
    "    ax3.set_ylabel(\"generational distance\")\n",
    "\n",
    "    ax4.plot(metrics.nfe, metrics.epsilon_indicator)\n",
    "    ax4.set_ylabel(\"epsilon indicator\")\n",
    "\n",
    "    ax5.plot(metrics.nfe, metrics.inverted_gd)\n",
    "    ax5.set_ylabel(\"inverted generational\\ndistance\")\n",
    "\n",
    "    ax6.plot(metrics.nfe, metrics.spacing)\n",
    "    ax6.set_ylabel(\"spacing\")\n",
    "\n",
    "ax6.set_xlabel(\"nfe\")\n",
    "\n",
    "\n",
    "sns.despine(fig)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MBDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
